{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前缀字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pfdict(f_name):\n",
    "    '''\n",
    "    生成前缀字典。\n",
    "    :param f_name:词典路径\n",
    "    :return lfreq, ltotal: {词：词频},总词频\n",
    "    '''\n",
    "    lfreq = {} #字典存储{词：词频}\n",
    "    ltotal = 0 #所有词总的出现次数\n",
    "    with open(f_name, 'rb') as f: # 打开文件词表f_name\n",
    "        for lineno, line in enumerate(f, 1): # 行号,行\n",
    "            try:\n",
    "                line = line.strip().decode('utf-8') # 解码为Unicode\n",
    "                word, freq = line.split(' ')[:2] # 获得词及其词频\n",
    "                freq = int(freq)#词频转成int型\n",
    "                lfreq[word] = freq#生成字典{词：词频}\n",
    "                ltotal += freq#统计所有词的词频\n",
    "                for ch in range(len(word)):# word的前缀词处理\n",
    "                    wfrag = word[:ch + 1]#前缀词\n",
    "                    if wfrag not in lfreq: # word前缀不在lfreq则其出现频次置0 \n",
    "                        lfreq[wfrag] = 0\n",
    "            except ValueError:\n",
    "                raise ValueError('invalid dictionary entry in %s at Line %s: %s' % (f_name, lineno, line))\n",
    "    return lfreq, ltotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfreq, ltotal = gen_pfdict('./data/dict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有向无环图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DAG(sentence):\n",
    "    '''\n",
    "    生成有向无环图。\n",
    "    :param sentence:待分词句子\n",
    "    :return DAG: 有向无环图{key:list,...},key:词的起始位置，list:从起始位置开始到以后位置可成词的位置。\n",
    "    '''\n",
    "    DAG = {}\n",
    "    N = len(sentence)\n",
    "    for k in range(N):\n",
    "        tmplist = []\n",
    "        i = k\n",
    "        frag = sentence[k]\n",
    "        while i < N and frag in lfreq:\n",
    "            if lfreq[frag]:#字典力有的才会添加到有向无环图里\n",
    "                tmplist.append(i)\n",
    "            i += 1\n",
    "            frag = sentence[k:i + 1]\n",
    "        if not tmplist:#字典里未登录的词，以孤立词添加到图里\n",
    "            tmplist.append(k)\n",
    "        DAG[k] = tmplist\n",
    "    return DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"去北京大学玩\"\n",
    "sentence = \"南京市长江大桥\"\n",
    "DAG = get_DAG(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2], 1: [1, 2], 2: [2, 3], 3: [3, 4, 6], 4: [4], 5: [5, 6], 6: [6]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态规划计算路径最大概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(sentence, DAG, route):\n",
    "    '''\n",
    "    使用动态规划方法，从后往前遍历，选择一个频度得分最大的一个切分组合。 \n",
    "    :param sentence,DAG:待分词句子,有向无环图\n",
    "    :return route: 分词的概率和路径\n",
    "    '''\n",
    "    N = len(sentence)\n",
    "    route[N] = (0, 0)\n",
    "     # 对概率值取对数之后的结果(可以让概率相乘的计算变成对数相加,防止相乘造成下溢)\n",
    "    logtotal = log(ltotal)\n",
    "    # 从后往前遍历句子 反向计算最大概率\n",
    "    for idx in range(N - 1, -1, -1):\n",
    "        # 列表推倒求最大概率对数路径\n",
    "        #log(self.FREQ.get(sentence[idx:x + 1]) or 1) - logtotal：sentence[idx:x + 1]的词频\n",
    "        # route[x+1][0] 表示 词路径[x+1,N-1]的最大概率对数\n",
    "        route[idx] = max((log(lfreq.get(sentence[idx:x + 1]) or 1) - logtotal + route[x + 1][0], x) for x in DAG[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = {}\n",
    "calc(sentence, DAG, route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: (0, 0),\n",
       " 6: (-8.863849339256593, 6),\n",
       " 5: (-9.813518371579148, 6),\n",
       " 4: (-19.011818225013663, 4),\n",
       " 3: (-9.653648934289546, 6),\n",
       " 2: (-16.96504852719957, 2),\n",
       " 1: (-26.084355807486915, 1),\n",
       " 0: (-19.941560115533193, 2)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据路径分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __cut_DAG_NO_HMM(sentence):\n",
    "    '''\n",
    "    根据分词路径分词处理。 \n",
    "    :param sentence:待分词句子\n",
    "    :return buf_list: 分词列表\n",
    "    '''\n",
    "    x = 0\n",
    "    N = len(sentence)\n",
    "    buf_list = []\n",
    "    while x < N:\n",
    "        y = route[x][1] + 1\n",
    "        l_word = sentence[x:y]\n",
    "        buf_list.append(l_word)\n",
    "        x = y\n",
    "    if buf_list:\n",
    "        return buf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['南京市', '长江大桥']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__cut_DAG_NO_HMM(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
