{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pinyin\n",
    "import jieba\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"./token_freq_pos%40350k_jieba.txt\"\n",
    "PUNCTUATION_LIST = string.punctuation\n",
    "PUNCTUATION_LIST += \"。，？：；｛｝［］‘“”《》／！％……（）\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取jieba词表\n",
    "def construct_dict( file_path ):\n",
    "\n",
    "    word_freq = {}\n",
    "    with open(file_path, \"r\",encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            info = line.split()\n",
    "            word = info[0]\n",
    "            frequency = info[1]\n",
    "            word_freq[word] = frequency\n",
    "\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_freq = construct_dict( FILE_PATH )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cn_words_dict( file_path ):\n",
    "    cn_words_dict = \"\"\n",
    "    with open(file_path, \"r\",encoding='UTF-8') as f:\n",
    "        for word in f:\n",
    "            cn_words_dict += word.strip()\n",
    "    return cn_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_words_dict = load_cn_words_dict( \"./cn_dict.txt\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(phrase, cn_words_dict):\n",
    "    \"All edits that are one edit away from `phrase`.\"\n",
    "    phrase = phrase\n",
    "    splits     = [(phrase[:i], phrase[i:])  for i in range(len(phrase) + 1)]\n",
    "    deletes    = [L + R[1:]                 for L, R in splits if R]\n",
    "    #print(\"deletes:\",deletes)\n",
    "    transposes = [L + R[1] + R[0] + R[2:]   for L, R in splits if len(R)>1]\n",
    "    #print(\"transposes:\",transposes)\n",
    "    replaces   = [L + c + R[1:]             for L, R in splits if R for c in cn_words_dict]\n",
    "    #print(\"replaces:\",replaces)\n",
    "    inserts    = [L + c + R                 for L, R in splits for c in cn_words_dict]\n",
    "    #print(\"inserts:\",inserts)\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edits1(\"我不好你\", \"你\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def known(phrases): \n",
    "    return set(phrase for phrase in phrases if phrase in phrase_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_candidates( error_phrase ):\n",
    "\n",
    "    candidates_1st_order = []\n",
    "    candidates_2nd_order = []\n",
    "    candidates_3nd_order = []\n",
    "    #print(error_phrase)\n",
    "    error_pinyin = pinyin.get(error_phrase, format=\"strip\", delimiter=\"/\")\n",
    "    #print(error_pinyin)\n",
    "    cn_words_dict = load_cn_words_dict( \"./cn_dict.txt\" )\n",
    "    candidate_phrases = list( known(edits1(error_phrase, cn_words_dict)) )\n",
    "    #print(candidate_phrases)\n",
    "    for candidate_phrase in candidate_phrases:\n",
    "        candidate_pinyin = pinyin.get(candidate_phrase, format=\"strip\", delimiter=\"/\")\n",
    "        if candidate_pinyin == error_pinyin:\n",
    "            candidates_1st_order.append(candidate_phrase)\n",
    "        elif candidate_pinyin.split(\"/\")[0] == error_pinyin.split(\"/\")[0]:\n",
    "            candidates_2nd_order.append(candidate_phrase)\n",
    "        else:\n",
    "            candidates_3nd_order.append(candidate_phrase)\n",
    "\n",
    "    return candidates_1st_order, candidates_2nd_order, candidates_3nd_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_correct( error_phrase ):\n",
    "\n",
    "    c1_order, c2_order, c3_order = get_candidates(error_phrase)\n",
    "    # print c1_order, c2_order, c3_order\n",
    "    if c1_order:\n",
    "        return max(c1_order, key=phrase_freq.get )\n",
    "    elif c2_order:\n",
    "        return max(c2_order, key=phrase_freq.get )\n",
    "    else:\n",
    "        return max(c3_order, key=phrase_freq.get )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_correct_sentence( error_sentence, verbose=True):\n",
    "\n",
    "    jieba_cut = jieba.cut( error_sentence, cut_all=False)\n",
    "    #print(list(jieba_cut))\n",
    "    seg_list = \"\\t\".join(jieba_cut).split(\"\\t\")\n",
    "    print(seg_list)\n",
    "    correct_sentence = \"\"\n",
    "\n",
    "    for phrase in seg_list:\n",
    "\n",
    "        correct_phrase = phrase\n",
    "        # check if item is a punctuation\n",
    "        if phrase not in PUNCTUATION_LIST:\n",
    "            # check if the phrase in our dict, if not then it is a misspelled phrase\n",
    "            if phrase not in phrase_freq.keys():\n",
    "                correct_phrase = auto_correct(phrase)\n",
    "                if verbose :\n",
    "                    print (phrase, correct_phrase)\n",
    "\n",
    "        correct_sentence += correct_phrase\n",
    "\n",
    "    return correct_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\86153\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.646 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['机七', '学习', '是', '人工智能', '领遇', '最能体现', '智能', '的', '一个', '分知', '！']\n",
      "机七 机器\n",
      "领遇 领域\n",
      "分知 分治\n",
      "original sentence:机七学习是人工智能领遇最能体现智能的一个分知！\n",
      "==>\n",
      "corrected sentence:机器学习是人工智能领域最能体现智能的一个分治！\n",
      "Test case 2:\n",
      "['杭洲', '是', '中国', '的', '八大', '古都', '之一', '，', '因', '风景', '锈丽', '，', '享有', '\"', '人间', '天棠', '\"', '的', '美誉', '！']\n",
      "杭洲 杭州\n",
      "锈丽 秀丽\n",
      "天棠 天堂\n",
      "original sentence:杭洲是中国的八大古都之一，因风景锈丽，享有\"人间天棠\"的美誉！\n",
      "==>\n",
      "corrected sentence:杭州是中国的八大古都之一，因风景秀丽，享有\"人间天堂\"的美誉！\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    err_sent_1 = '机七学习是人工智能领遇最能体现智能的一个分知！'\n",
    "    print (\"Test case 1:\")\n",
    "    correct_sent = auto_correct_sentence( err_sent_1 )\n",
    "    print (\"original sentence:\" + err_sent_1 + \"\\n==>\\n\" + \"corrected sentence:\" + correct_sent)\n",
    "\n",
    "    err_sent_2 = '杭洲是中国的八大古都之一，因风景锈丽，享有\"人间天棠\"的美誉！'\n",
    "    print (\"Test case 2:\")\n",
    "    correct_sent = auto_correct_sentence( err_sent_2 )\n",
    "    print (\"original sentence:\" + err_sent_2 + \"\\n==>\\n\" + \"corrected sentence:\" + correct_sent)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #reload(sys)\n",
    "    #sys.setdefaultencoding('utf-8')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
